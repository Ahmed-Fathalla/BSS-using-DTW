{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37294024",
   "metadata": {},
   "source": [
    "# Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c01329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install similaritymeasures\n",
    "# !pip install scikit-learn-extra\n",
    "# !pip install geopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a9862b",
   "metadata": {},
   "source": [
    "# Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613daf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step_1: Download data From: https://www.kaggle.com/datasets/akkithetechie/new-york-city-bike-share-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4056f655",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b6efd05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T20:24:14.987158Z",
     "start_time": "2024-05-13T20:24:05.637417Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from Bike_utils_similarity.Exp import *\n",
    "from Bike_utils_similarity.counter import *\n",
    "from Bike_utils_similarity.extra_utils import data_partition,write_\n",
    "from Bike_utils_similarity.utils.pkl_utils import *\n",
    "from Bike_utils_similarity.utils.time_utils import get_TimeStamp_str\n",
    "from Bike_utils_similarity.utils.distance_extraction import get_distance\n",
    "from Bike_utils_similarity.similarity_utils import similarity, get_hours_curve_data\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9092f09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:52:13.952999Z",
     "start_time": "2024-05-08T14:52:10.424811Z"
    }
   },
   "outputs": [],
   "source": [
    "# --------------- 1 start\n",
    "df = pd.read_csv('NYC-BikeShare-2015-2017-combined.csv')\n",
    "\n",
    "for f in ['User Type']: # 'Start Station Name' ==> \"moved commented\" ==> Mon_2024_5_6__12_20_49\n",
    "    le = LabelEncoder()\n",
    "    df[f] = le.fit_transform(df[f])  \n",
    "\n",
    "a = pd.to_datetime(df['Start Time'])\n",
    "df['DO_week'] = a.dt.day_of_week\n",
    "df['DO_month'] = a.dt.day\n",
    "df['month'] = a.dt.month\n",
    "df['hour'] = a.dt.hour\n",
    "df['min'] = a.dt.minute\n",
    "df['year'] = a.dt.year\n",
    "\n",
    "df['age'] = df['year'] - df['Birth Year']\n",
    "\n",
    "df['Start Hour'] = a.dt.hour \n",
    "# --------------- 1 end   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcbb516",
   "metadata": {},
   "source": [
    "## Encoding \"Start\" & \"End\" Station_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ccaf9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:52:23.993316Z",
     "start_time": "2024-05-08T14:52:13.955185Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fathalla\\AppData\\Local\\Temp\\ipykernel_24752\\2461915161.py:5: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  mappping_dic = dd.set_index('Start Station Name').T.to_dict('list')\n"
     ]
    }
   ],
   "source": [
    "# ========== mappping_dic ===============================\n",
    "# --------------- 2 start \n",
    "e = LabelEncoder()\n",
    "df['Start Station Encoding'] = e.fit_transform(df['Start Station Name'])    \n",
    "dd = df[['Start Station Name', 'Start Station Encoding']]\n",
    "mappping_dic = dd.set_index('Start Station Name').T.to_dict('list')\n",
    "# dump(mappping_dic,'mappping_dic')\n",
    "\n",
    "for k,v in mappping_dic.items():\n",
    "    mappping_dic[k] = v[0]\n",
    "    \n",
    "def custom_encoding(x):\n",
    "    return mappping_dic[x] if x in mappping_dic.keys() else -1\n",
    "\n",
    "df['End Station Encoding'] = df['End Station Name'].apply(lambda x:custom_encoding(x))\n",
    "df = df[~(df['End Station Encoding']==-1) ]\n",
    "dump(mappping_dic,'mappping_dic')\n",
    "# --------------- 2 End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e1f4095",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:54:24.520490Z",
     "start_time": "2024-05-08T14:52:23.995036Z"
    }
   },
   "outputs": [],
   "source": [
    "# --------------- 3 Start: Calc Distance\n",
    "from Bike_utils_similarity.utils.distance_extraction import get_distance\n",
    "df['distance'] = df[['Start Station Latitude',\n",
    "                     'Start Station Longitude',\n",
    "                     'End Station Latitude',\n",
    "                     'End Station Longitude']].apply(lambda x: get_distance(x), axis=1)\n",
    "# --------------- 3 End"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a37500",
   "metadata": {},
   "source": [
    "# Save Modified DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c71ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('NYC-BikeShare-2015-2017-modified.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81427951",
   "metadata": {},
   "source": [
    "# Steps for the proposed method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b54b7223",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:57:07.079220Z",
     "start_time": "2024-05-08T14:57:06.893122Z"
    }
   },
   "outputs": [],
   "source": [
    "# --------------- 4 start    \"dic.csv\"\n",
    "count = 0\n",
    "l=[]\n",
    "for i in range(len(mappping_dic)):\n",
    "    for j in range(i, len(mappping_dic)):\n",
    "        l.append(['%d-%d'%(i,j), count])\n",
    "        count+=1\n",
    "dic_ = pd.DataFrame( np.array(l), columns = ['key', 'value'])     \n",
    "dic_.to_csv('dic.csv', index=False)\n",
    "# --------------- 4 End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5badec79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:57:54.774139Z",
     "start_time": "2024-05-08T14:57:50.256541Z"
    }
   },
   "outputs": [],
   "source": [
    "# --------------- 5 start: Count number of trips between two stations\n",
    "data_partition_ = data_partition(df.copy())\n",
    "\n",
    "v_lst = list(mappping_dic.values())\n",
    "z = np.zeros((len(v_lst), len(v_lst)), dtype=int)\n",
    "mappping_dic = load_pkl('mappping_dic') # =======================================\n",
    "\n",
    "for i in range(len(mappping_dic.values())):\n",
    "    for j in range(i, len(mappping_dic.values())):\n",
    "        z[i,j] = data_partition_.get_data( v_lst[i], v_lst[j], info_='shape')\n",
    "        \n",
    "d = pd.DataFrame(z, columns=v_lst)\n",
    "d.to_csv('Trip count_martix.csv', index=False)        \n",
    "# --------------- 5 End    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b2d3d27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T14:58:43.967600Z",
     "start_time": "2024-05-08T14:58:43.690948Z"
    }
   },
   "outputs": [],
   "source": [
    "# --------------- 6 start - Generate Curves data\n",
    "Conf_matrix_cell_curve_data = {}\n",
    "v_lst = list(mappping_dic.values())\n",
    "data_partition_ = data_partition(df.copy())\n",
    "\n",
    "for i in range(len(mappping_dic.values())):\n",
    "    for j in range(i, len(mappping_dic.values())):\n",
    "        dframe = data_partition_.get_data( v_lst[i], v_lst[j], info_='data')\n",
    "        Conf_matrix_cell_curve_data['%s-%s'%(i,j)] = get_hours_curve_data(dframe)\n",
    "        \n",
    "dump(Conf_matrix_cell_curve_data,'Conf_matrix_cell_curve_data')        \n",
    "# --------------- 6 End  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61490b85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T20:45:33.931310Z",
     "start_time": "2024-05-07T20:37:46.454463Z"
    }
   },
   "outputs": [],
   "source": [
    "# --------------- 7 start - \"dist_matrix\"\n",
    "Conf_matrix_cell_curve_data = load_pkl('Conf_matrix_cell_curve_data')\n",
    "k_lst = list(Conf_matrix_cell_curve_data.keys())\n",
    "dist_matrix = np.zeros((len(k_lst),len(k_lst)))\n",
    "\n",
    "similarity_ = similarity(Conf_matrix_cell_curve_data)\n",
    "\n",
    "for i in range(len(k_lst)):\n",
    "    for j in range(i+1, len(k_lst)):\n",
    "        x = similarity_.calc_similarity(k_lst[i], k_lst[j]) \n",
    "        dist_matrix[i,j] = x\n",
    "        dist_matrix[j,i] = x\n",
    "dist_matrix = pd.DataFrame( np.array(dist_matrix) )\n",
    "dist_matrix.to_csv('dist_matrix.csv', index=False)\n",
    "# --------------- 7 End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66a40711",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T21:20:56.336482Z",
     "start_time": "2024-05-07T21:20:53.824403Z"
    }
   },
   "outputs": [],
   "source": [
    "# --------------- 8 \"clustering.pkl\"  KMedoids: \n",
    "dist_matrix = pd.read_csv('dist_matrix.csv',index_col=None)\n",
    "res={}\n",
    "for i in range(2,11):   \n",
    "    model = KMedoids(n_clusters=i, random_state=0).fit(dist_matrix)\n",
    "    res[str(i)]=model.labels_\n",
    "dump(res, 'clustering') #    of length 1326 \n",
    "# --------------- 8 End  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef95b111",
   "metadata": {},
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e7936ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:03:36.633146Z",
     "start_time": "2024-05-08T10:54:16.314861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tcluster_df.shape ---------- cluster_id:0 (1230, 3)   DF length: 601156 \n",
      "\tcluster_df.shape ---------- cluster_id:1 (96, 3)   DF length: 133984 \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('NYC-BikeShare-2015-2017-modified.csv')\n",
    "dic_df = pd.read_csv('dic.csv')\n",
    "res = load_pkl('clustering')\n",
    "\n",
    "data_partition_ = data_partition(df.copy())\n",
    "\n",
    "cluster_df = None\n",
    "\n",
    "for i in range(2,3):\n",
    "    \n",
    "    exp_df = None\n",
    "    results = []\n",
    "    tmp = dic_df.copy()\n",
    "    tmp['cluster'] = res[str(i)]\n",
    "    cluster_id_results = []\n",
    "    \n",
    "    for cluster_id in set(res[str(i)]):\n",
    "        cluster_df = tmp[tmp['cluster']==cluster_id]\n",
    "        cluster_id_df = pd.DataFrame()\n",
    "        \n",
    "        for k in cluster_df['key'].values: # \n",
    "            w = [int(w) for w in k.split('-')]\n",
    "            sub_df = data_partition_.get_data(w[0], w[1], info_='data')\n",
    "            cluster_id_df = pd.concat([cluster_id_df, sub_df])\n",
    "        \n",
    "        # train and predict the data =====================================================================\n",
    "        write_('output','\\tcluster_df.shape ---------- cluster_id:%d'%cluster_id , cluster_df.shape, \"  DF length:\", cluster_id_df.shape[0] )\n",
    "        exp_res = ML_exp(cluster_id_df, \n",
    "                         start_model=0, \n",
    "                         end_model=10,\n",
    "                         cluster='Clustering:%d-k:%d'%(i,cluster_id))\n",
    "        \n",
    "        # get the results =====================================================================\n",
    "        cluster_id_results.extend(exp_res)\n",
    "    \n",
    "    all_res = pd.DataFrame(np.array(cluster_id_results), columns=results_cols)\n",
    "    all_res.to_csv('cluster %d - %s.csv'%(i,get_TimeStamp_str()), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7db1340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5746013a",
   "metadata": {},
   "source": [
    "# ALL Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470023ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bike_utils_similarity.Exp import *\n",
    "from Bike_utils_similarity.extra_utils import data_partition,write_\n",
    "from Bike_utils_similarity.utils.pkl_utils import *\n",
    "from Bike_utils_similarity.utils.time_utils import get_TimeStamp_str\n",
    "# from Bike_utils_similarity.utils.distance_extraction import get_distance\n",
    "from Bike_utils_similarity.similarity_utils import similarity, get_hours_curve_data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('NYC-BikeShare-2015-2017-modified.csv')\n",
    "\n",
    "exp_res = Similarity_ML_exp(df, \n",
    "                            start_model=0, \n",
    "                            end_model=10,\n",
    "                            cluster='all_data')\n",
    "\n",
    "all_res = pd.DataFrame(np.array(exp_res), columns=results_cols)\n",
    "all_res.to_csv('cluster-2015-2017 all_data - %s.csv'%(get_TimeStamp_str()), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
